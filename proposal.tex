\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{mathtools}

\title{Network Security Analytics}
\author{Sunil Pedapudi \qquad Matthias Vallentin\\
\small \texttt{\{sunil, vallentin\}@cs.berkeley.edu}
}
\date{}

\def\first{\emph{(i)}~}
\def\second{\emph{(ii)}~}
\def\third{\emph{(iii)}~}
\def\fourth{\emph{(iv)}~}
\def\fifth{\emph{(v)}~}
\def\todo#1{\textit{\textcolor{red}{TODO: #1}}}
\def\xref#1{\S\ref{#1}}

\begin{document}
\maketitle

\section{Problem Statement}

Incident response, post-facto forensics, and network troubleshooting rely on
the ability to quickly extract relevant information. To this end, security
analysts and network operators need a system that \first allows for directly
expressing a query using domain-specific constructs, and \second delivers the
performance required for interactive analysis. The database community offers an
abundance of tuned niche solutions that claim to address the latter aspect, but
the overwhelming majority of these works are not available as stable
open-source packages, fail to deliver the advertised performance with workloads
from our domain, or have inherent limitations in the expressiveness of their
data model.

Therefore, we started to build our own system that supports the field's common
idioms and exhibits a scalable architecture capable of handling the large,
continuously arriving data. In previous work, we designed and implemented a
prototype whose storage layer was not well-suited for distributed deployment.
In this project, we aim to continue this effort by redesigning and
implementing the building blocks of the underlying storage system while
considering cutting-edge distributed database technology. 

Network security analysis generates large volumes of rich-typed,
semi-structured log data~\cite{Melnik10}. Existing tools do the heavy lifting
of extracting this fine-grained data~\cite{Paxson99} which we would like to
archive permanently. In the case of incident response, the analysis procedure
often begins with a piece of intelligence, such as ``this MD5 hash of a file is
malware,'' or ``connections to IP address $X$ contain botnet traffic.'' An
analyst uses this information to identify affected machines in the own network,
quarantine them, and investigate the collateral damage. This process involves
filtering the data (project, select) and computing aggregates (sum, quantile,
top-$k$, unique) interactively. The analysis proceeds in an ad-hoc fashion and
may involve several refinements until the full extent of an incident has been
determined. Our goal in this project is to build a system that can handle this
use case with real-world data from UC Berkeley's 10-Gbps upstream link.

\section{Roadmap}
%\label{sec:road}

%We set out to explore a non-relational design that allows for rich data models
%and lends itself to distributed query processing. This element of the project
%identifies what basic blocks of storage are necessary to preserve
%application-specific semantics as network events are committed to persistence. 

%% The following describes basic
%% components of storage that facilitate query processing over semantically rich
%% data. 
%% \begin{description}
%%   \item[Events] are the highest granularity of components that are stored
%%     in VAST. Each source that wishes to contribute to the VAST corpora generates
%%     highly structured objects that correspond to network events.
%%   \item[Tablets] encompass several events that characteristically merit locality
%%     and can thus be grouped together. Within a tablet, it is possible to select
%%     columns of data spanning several events, and this provides efficient
%%     primitives for query processing. Currently, tablets will represent a small
%%     time range, and we assign each tablet a UUID to later identify them. 
%%   \item[Multiple indices] are not stored primitives per se, but they are
%%     essential in data look-up and can contribute to efficient processing.
%%     Multiple indices will also aid in preserving the semantic richness of data
%%     by encompassing information relating multiple events. For example, discrete
%%     events may belong to the same TCP stream, and we may be able to provide an
%%     index where a set of events are associated with unique TCP steams.
%% \end{description}

Given a rich model data, we aim to identify a storage architecture that meets
interactive query response times with simultaneous high-throughput archival.
The goal is to create a hybrid system that supports both queries on
historical data as well as incoming streaming data, and to do this, the
naturally parallel nature of non-relational data stores provide an ideal
starting point. We plan to expand on these systems by providing indexes and
efficient range scans. This architecture should provide modularity and
horizontal scalability such that different workloads can adopt varying
deployment sizes without needing to modify the core design of the system.

As a short-term goal, we intend to support selections and projections
over data with interactive query response times. Leveraging knowledge from
current database research, we also design a distributed query architecture
that we aim to implement with a SQL-like interface to the end user.

%\subsection{Forensics and Incident Response}
%\label{sec:eval:forensics}
%To validate the effectiveness of VAST, we will present a data exploration task and
%show how VAST facilitates navigation of the data in a flexible manner. This suggests
%we identify a metric of interactivity for network forensics as well as describe
%enabling primitives provided by VAST for pinpointing network events. If mature, we
%will show incident response schemes that can programatically identify events of
%forensic interest. 

\section{Related Work}

\begin{description}
\item[DBMS and DSMS]
Traditionally, data base management systems support historical queries over
already-archived data while data stream management systems support live queries
that incorporate newly arriving data after a query is issued. We merge these
into a hybrid system~\cite{Reiss07} much like TelegraphCQ~\cite{Chandrasekaran03}.

\item[OLAP]
An alternative perspective of the query workload that we support is described
by online analytical processing systems which, given a database warehouse of
bulk-loaded data, allow for immutable data processing. However, our system
differs fundamentally from existing OLAP systems in supporting side-by-side
execution of both queries and data archival.

\item[NoSQL]
To meet performance goals of online data reporting, we will explore works of
``Not only SQL'' or ``non-relational'' storage engines~\cite{Cattell10} for
inspiration towards horizontal scalability. Ideally, NoSQL storage engines
allow for simultaneous reads and writes of parallel data streams due to the
data access patterns they allow. For the same reason, we surmise that NoSQL
storage will also help address the challenge of performing data archiving in
light of expansive amounts of incoming data.

\item[Network Security]
The Time Machine~\cite{Maier08} records raw packet-level network
traffic for future inspection. Time Machine is similar to our approach in that
it handles a high-performance network traffic stream, indexing, and retrieval;
we extend these concepts to arbitrary events that can stem from a wide range
of sources. Further, a major limitation of Time Machine is that it works only on
a local machine while we aim to scale in a cluster setting.

\end{description}

\bibliographystyle{abbrv}
\bibliography{../vast}

\end{document}
